================================================================================
Call: Noble Schools <> Hiver AI
Date: 2026-01-30T21:39:18+05:30
================================================================================

Raghav Shankar (raghav@hiverhq.com):
  chase, hi, can you hear me? Yeah, I can hear you. I'm really sorry, chase, my previous meeting ran over and then I just was able to wrap it up and hop on. Hope I didn't take too much of your time today. No, I stayed productive. Don't worry. Thank you so much.

Raghav Shankar (raghav@hiverhq.com):
  So, chase, you know, there were two things that we left it with our last discussion, first on the pricing part. I'm sure you would have realized this by now but you're good till the contract renews, obviously because we signed it up in advance. So no need to worry about any price increases till the expiry of the overall contract, which means 27, right? So I wanted to start with that guarantee because I realized I didn't put that in an email like I said, so thought I'd tell you directly now with that said talking about AI as a whole and in terms of feature functionality that I wanted to chat with you about two core pieces of AI that I wanted to showcase to just get you started in terms of exploring and see if it makes sense. Both of these are part of your existing tiers. Obviously, you don't have to upgrade or talk about any commercials immediately to explore them or start using them as well. The first AI functionality that I wanted to showcase and let me get my screen share up and running as well.

Raghav Shankar (raghav@hiverhq.com):
  So there is a visual cue for this. The first one is something that we're calling ask AI or AI copilot, right? Think of this as a hiver created conversational assistant, right? I wouldn't necessarily call it like a gemini or chatgpt but it's like halfway there, but it is more contextual, purpose built for your team and will exclusively be trained on the material you provide. Now, the way it works is basically whenever an agent on your team opens an email, it will be this little sparkle icon that sticks on the bottom, right? Pop it open and it gives a place where the agents can one ask questions back and forth saying, hey, by policy by the way we handle it by a process. Is this what I should be doing here, right? And, you know, the assistant would be able to give you that information, like for instance, just going to be like, hey, what's the pricing for the pro plan, right? That's one of the material we've uploaded and you'll notice that it checks our knowledge bases that we've given it. It's guardrailed purely within that scope of it. So it's not finding random stuff and it's not hallucinating, obviously, right? And it would be able to tell you exactly what that looks like, where you can see it from how you can address it. Stuff like that. Now, with that said, it also gives you information like this, like for instance, hey, maybe your source needs updating because it doesn't have this exact information you're looking for, right? And gives you that feedback loop to go ahead… likes or dislikes. So that way the entire feedback loop is handled. So every single agent can and would be able to give it feedback in terms of improving the experience as a whole. Now, by and large, some of the things it does, one of it is obviously the semi conversational space where you pump in like 10 15 documents and it can keep it going. The second thing copilot can do is obviously summarize it with action steps and next steps. So instead of being, you know, like gemini does 10 bullet points, five bullet points. Whatever the summarizer within ask AI actually starts with a quick three line of, hey, this has been the problem so far on the email isolates. The actual issue, tells you these were the steps that were taken by your team purely based on the email exchange so far tells you the current status and tells you next steps based on, and this is where again the knowledge sources come in handy, tells you, hey, in this scenario, your team typically does step one, step two, step three or action one, action two. Check it out. Now as the last piece. Obviously, as you'd expect from any AI assistant, it would be able to draft a reply for you as well. So it kind of doubles down as a reply drafting assistant looks at the context of the email, the entire email chain to be precise. And then starts generating a reply that your team can use as is by just inserting it, they can take another pass at it and say refine it with my knowledge base or knowledge documents and makes it better if there's a departure or change that needs there. And obviously, as you would expect there is more customization across the whole thing. So when it comes to the co, pilot piece as a whole because it's so reliant on your data sources in itself, you can either upload documents as they are copy paste snippets or best responses that you want for like specific scenarios, we have notion as a direct connector right now that's out, we're working on clickup confluence and Google drive as the immediate items for the rest of this quarter. So whenever each of them is ready, they would show up here as external sources connections, which means for you upload it on a Google drive or Google doc, first connect it to hiver as a whole. And that way you upload it on the document, your agents are now going to get the most updated version through the co pilot experience, right? So that's how the knowledge can be controlled in terms of what AI is trained on. The second thing you can do is handle the persona. So the way the replies are drafted, so you've got tonalities you can choose from as defaults out of the box or custom type out a certain tone, a certain way in which you'd like for your replies, responses and summaries to be drafted in when the agent gets to see it. So personalization on tonality is possible. And lastly, we've just launched this review module as well. So, remember how I showed you the thumbs up, thumbs down piece. Whenever that happens, you get to see all right, these were the things that were flagged by the team when they were individually interacting with the co pilot. And that way you would also get to see a sense of all right, maybe for this scenario, we need a different document, right? We can upload it. We can increase it, things like that. But all of this is just more from a visibility perspective in terms of reviewing. So the AI is still working in the background, improving itself, understanding better responses and just making sure it's tuned and tuning itself continuously on being more contextual for your team, right? So that's a quick 30 second full picture on the ask AI piece or the AI co pilot as a whole. I'm just gonna pause to check if this rings a bell, if you think this will be useful for the team at least in terms of just looking stuff up.

Chase Espinoza-Johnson (cespinozajohnson@nobleschools.org):
  Yeah, I definitely think it will be. I don't I know I uploaded some nod choices a long time ago.

Raghav Shankar (raghav@hiverhq.com):
  Oh, do you want to share your screen that's easier? But.

Chase Espinoza-Johnson (cespinozajohnson@nobleschools.org):
  I don't think I ever did anything after that, so I think I started it and.

Raghav Shankar (raghav@hiverhq.com):
  Didn't finish it.

Chase Espinoza-Johnson (cespinozajohnson@nobleschools.org):
  Okay. So I have six files, but haven't actually done anything with them.

Raghav Shankar (raghav@hiverhq.com):
  Okay. Cool. Well, now's a great time to try it out because as of December, what we've done is we've also moved the foundational model for our hiver AI as a whole to gpt fivo, so we've upgraded it to the most latest model by openai. And we've added different levels of context training, guardrails and response training as well. All of this to basically say now when you query, it might be different from what you might have received two, three months back if you had a chance to check it out. Right? The second thing we've also done is we're now open to tweaking the understanding of copilot as well. So once you try it out a few times and you're like, hey, it's missing the mark. It's not looking at point one or not looking at something specific, let us know, and we'll work from the background to tweak the experience. So it comes to a stage where you feel comfortable letting the agents use it to just get the replies going in that sense, right? That's also doable. Another support we've added here is copilot can also track images or wouldn't say track, but understand images that you receive. So attachments, screenshots, things like that could also be fed to copilot on the email itself. So be like, all right, this is the context, attach the document and be like use the document to draft the reply or to tell me next steps. So all of that is also possible. I think you're on the right track with getting the documents there. I think at this point, it's just going to be about testing it out maybe a bunch of times. And then we reconnect and we look at feedback and optimization from there. Okay. Sounds good. Brilliant. All right. The next thing that I wanted to show you is going to be part of your and I'm going to switch to my screen in just a quick minute. This is the one that we're calling AI agents primarily. And this is going to be an assistant within your automations or creating the workflows as a whole. All right now, yeah back to my screen. So all this while we've been using keywords and automations primarily as the differentiator or the identifier meaning the presence of a keyword, the absence of a keyword, a certain domain and things like that. Two advantages for you right now, one is so far we had 20 rule based automations on pro. That's now going to go to 30 rule based automations because we've signed the multi year contract. I'll work with my team and make sure you get that 10 extra unlocked so you can explore this. And with that said AI tasks as we're calling it the ones within the automation, what it lets you do now is be more generic and conversational with the automations you're trying to do. So at this stage, what you can do is ask AI to effectively extract what you're looking for. So in this case, let's say I'm trying to find this code name, location and department. Just an example. Let's say I get an email and I want to find these three pieces of information on every email I get you're. Now able to configure this as a workflow where AI can run through the subject in the body at this point, extract these pieces of information based on which you can now start performing actions. Now, if you just like for this information to be accessible to your individual team members, then you're seeing. All right, you're extracting the name, location and department. Okay, hiver. I just want you to add a note saying school name is this location is here. Department. Is this, you can keep it as simple as that. But you could also automate actions based on the results. For example, we can say, hey, if the department is computer science or if it is, I don't know humanities. Maybe as a whole. Now, if it's an email from any of these two departments specifically, then I want hiver to perform a set of actions, automatic reminder, retagging it, reassigning it, you know, sending a notification, things like that are all possible, right? So that's one of the ways in which you can think about AI tasks and run a couple of scenarios as examples to see what it does very soon. We're also going to be making this AI variable piece a dynamic part of it. So right now, it's static in the sense it gets the values you predetermine if it's value one two three, do an action. Now, in the next couple of weeks, we're going to be launching the second version of this where you can say, here are the values between this to this, then do action one, if it's between a second range, do action two. So we are going to make it dynamic. It's going to be out in like a couple of weeks. As of today, static gets the right information, either shows it as display only and based on selective options, you can then have it perform actions as well. So that was the second big piece of AI that I wanted. To showcase, I think I might have oversimplified it because, you know, we're done already, but, you know, in terms of AI tasks, specifically, some of our largest human resources related departments and teams on hiver have actually started extracting more value from it with complex workflows and things like that. And considering how we've always relied on keywords so far, I thought I'd give you this option for you to start thinking about and exploring. And then we'll chat in detail about what this looks like, what it entails in the long run for you. So those are the two main pieces of AI that you have access to part of your tiers and you can start using whenever you're ready. AI tagging obviously is also something you have access to. So this is where you no longer need to do keywords for tagging from your nodding. I think you're understanding what that looks like and works. So, yeah, basically, you either pick a tag you already have or create one new, give the AI the training. And that happens by adding the tag manually to 10 emails, could be old, could be new emails that doesn't make a difference. You're just training the model by saying, hey, here's, 10 descriptions or scenarios far and wide that covers the breadth of this tag. Once it's done, you get to see the training data, refine it whenever you want to. Essentially, once it's enabled and ready to go, AI just starts adding that tag whenever it feels the scope matches and the tweaking can just happen by keywords as prompt engineering. So you can just be like, all right, also include this scenario and gets it included there. So even with the tagging, there's going to be that thumbs up, thumbs down review mechanism. So nothing on hiver, AI is set in stone. Every agent that interacts with it can keep giving that feedback loop. So it keeps getting trained basically. But AI tagging as a whole might free up some workflow rules space for you when it's there, so that you don't have to use it just for adding a tag. Yep, sentiment. I'm not entirely sure to what extent it will be useful, but it is a way where you can track… the sentiment on your incoming emails on either a three or five point scale. Refinement is possible again based on prompts. So you can be like scenario one two three, like somebody's annoyed about not getting access, that needs to be a negative sort of scale of how we want to track it as a team, right? So you can tweak it based on it, you can make these. So these are visual cues. There's going to be little emojis that start showing up on emails once it's enabled. But if you feel that might be intrusive or detrimental for the team to see that when they're working on it, you can just let this run in the background, create a workflow based on the sentiment. And it's just not going to show up. When you view that email in bulk, it'll just be visible when you open it one email at a time. That's also something you could do. So that these four pretty much encapsulate the major AI features that I wanted to quickly highlight for today. Just to get you started on them. There's obviously some AI that we're building for our elite plan. Exclusively. One of that is aiqa, which is a way where you can tweak custom build a way to track the outcomes that your teams are driving on emails, spellcheck grammar, pretty standard stuff, but it also dives into tonality, clarity, completeness of the response, things like that as well. You can exclude domains from being used here. Long term, we're looking at aiqa as a means to help an agent while they type in a reply, but also give team leads an understanding of how can we make them perform better? If that's a signal? You want to track another thing that we're building which is not on my sandbox yet is AI insights. Reporting. Now on hiver. Would also have an element where an entire reporting module is built purely driven by AI, where it ingests your incoming emails, categorizes it by themes, sub themes, the general sentiment, when your team addresses that theme, the outliers, a lot of things like that. But for now on the sentiment or rather the insights piece of it, I'm going to reserve it for the time being just because I don't have anything visual to show you what we can do right now. And this again part of your existing tier is sentiment reporting would be there. So once enabled, you get to see what that tracking looks like and QA, if you're interested and you want to start tracking it. Once enabled. Again, this is what that reporting piece of it would look like agent name the different categories you're tracking for their score per email on how they've been handling it, what they've done here, what's missing? So that's the depth of the whole thing. And yeah, like long story short. Those were the four main features that I wanted to showcase out of which two are very brand new, especially the QA. The ask AI and the AI tasks. So, yeah, I'd like for you to like check it out.

Raghav Shankar (raghav@hiverhq.com):
  Think about it. We can probably reconnect in like two to three weeks from now. So you have some time, I'll send over knowledge base articles, so you can read about it while you're setting it up and we'll reconvene in like three weeks, see how it's coming along and we can start talking about some workflows unless you have any top of mind right now, you'd.

Chase Espinoza-Johnson (cespinozajohnson@nobleschools.org):
  like to chat about not top of mind, but I'm excited to start playing around with the new features. This is awesome.

Raghav Shankar (raghav@hiverhq.com):
  Brilliant. All right, chase. I appreciate you sticking around while I was late by 10 minutes, so, no.

Chase Espinoza-Johnson (cespinozajohnson@nobleschools.org):
  Worries. Have a good day.

Raghav Shankar (raghav@hiverhq.com):
  You too. Chase. Have a good weekend. Bye.
